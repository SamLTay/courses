---
title: "Activity Tracker Exercise Prediction"
author: "Sam Tay"
date: "June 29, 2018"
output: html_document
---

# PGA-ML project
## Introduction
The data set consists of realtime measurements and summarised data.  
Those realtime measurements are the raw data where these summarized data
like mean, standard deviation, kurtosis, skew, max, min etc are derived.
As information on the realtime data have all the information in the 
summarized data, I proceeded to use only the realtime data for training
of the model and testing.  I also removed the time stamps, user names, window number from the data set and left with numerical data of the measurements with "classe" classification.  In the 20 sets of test data provided, the "classe" data is not included.  I used its "num_window" and "user name" to create an additonal column "classe" for validation. Two methods will be covered with the first using selected 28 predictors and random forest processing followed by using 4 top Principal Components from the full data set and random forest processing.
I have also include the result summaries of Linear Discrimination Analysis and Naive Bayes at the end of the note.


```{r setup, echo=FALSE,include=FALSE}

library("caret")
library("dplyr")
```

```{r readfile,echo=TRUE}
actTrack<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
x<-is.na(actTrack[,1:160])|actTrack[,1:160]=="#DIV/0!"
y<-colSums(x)==0

# create a set of variables in data frame aTdata1 excluding those columns
# with occurance of NA or #DIV/0!

aTdata1<-actTrack[,y]
aTdata10<-aTdata1[,-c(1:7)]
# aTdata10 is numeric dataframe for PCA processing
```

## Data Exploration

Investigate predictor Classe in relation with other predictors

```{r Relation.between.Classe.vs.num_win.and.user_name}
#############################
#verify that num_window and user_name uniquely determine Classe
# [1] "TRUE if num_window and user_name uniquely determine Classe"
# [1] TRUE
# start verification

aTdata1$uw<-paste(aTdata1$user_name,aTdata1$num_window)
aTdata1$uwc<-paste(aTdata1$user_name,aTdata1$num_window,aTdata1$classe)
u2<-unique(aTdata1$uw)
u3<-unique(aTdata1$uwc)
print("TRUE if num_window and user_name uniquely determine Classe")
print(length(u2)==length(u3))

#restore aTdata1 back to one without predictors "uw" and "uwc"

aTdata1<-aTdata1[,-c(61,62)]

# end of verification ########
```

## 1.  Use selected 28  predictors for Random Forest Processing
```{r 28predictors.Random.Forest, cache=TRUE}
# select variables related to the paper Section 5.1 Feature Extraction and Selection.
# Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. 
# Qualitative Activity Recognition of Weight Lifting Exercises. 
# Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . 
# Stuttgart, Germany: ACM SIGCHI, 2013. 
# http://groupware.les.inf.puc-rio.br:80/public/papers/2013.Velloso.QAR-WLE.pdf
# in the paper, 17 features are selected which are closely related to 
# the following time series measured parameters which are short listed as predictors here
# [1] "roll_belt"            "gyros_belt_x"         "gyros_belt_y"        
# [4] "gyros_belt_z"         "accel_belt_x"         "accel_belt_y"        
# [7] "accel_belt_z"         "magnet_belt_x"        "magnet_belt_y"       
# [10] "magnet_belt_z"        "accel_arm_x"          "accel_arm_y"        
# [13] "accel_arm_z"          "magnet_arm_x"         "magnet_arm_y"       
# [16] "magnet_arm_z"         "total_accel_dumbbell" "gyros_dumbbell_x"  
# [19] "gyros_dumbbell_y"     "gyros_dumbbell_z"     "magnet_dumbbell_x" 
# [22] "magnet_dumbbell_y"    "magnet_dumbbell_z"    "pitch_forearm"     
# [25] "gyros_forearm_x"      "gyros_forearm_y"      "gyros_forearm_z"    
# [28] "classe"  
# which are in columns of c(8,12:20,28:30,31:33,37:40,44:46,48,51:53,60) # in aTdata1 
# and store them in aTdata4

sel<-c(8,12:20,28:30,31:33,37:40,44:46,48,51:53,60)
aTdata4<-aTdata1[,sel]

#Random Forest Processing by training 75% of aTdata4 set aside as training
# Test was performed on the rest of 25% of aTdata4 set aside as testing
set.seed(1234)
inTrain<-createDataPartition(y=aTdata4$classe,p=0.75,list=FALSE)
training<-aTdata4[inTrain,]
testing<-aTdata4[-inTrain,]

Modfit<-train(classe~.,data=training,method="rf",proxy=TRUE)
pRf<-predict(Modfit,testing)
print(table(pRf,testing$classe))
print(confusionMatrix(pRf,testing$classe))

```

## 1.1  Validating the model with the 20 sets of test data provided
```{r Test Set}
#  selecting the 20 testing sets provided for validation
actTrack2<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
testing2<-actTrack2[,y]

a<-mutate(aTdata1,uw=paste(classe,user_name,num_window))
g<-group_by(a,uw)
uq<-unique(g$uw)
sp<-strsplit(uq," ")
i=1
ref=NULL
for (i in 1:length(sp)){
  ref$classe<-c(sp[[i]][1],ref$classe)
  ref$user_name<-c(sp[[i]][2],ref$user_name)
  ref$num_window<-c(sp[[i]][3],ref$num_window)
  ref$uw<-c(paste(sp[[i]][2],sp[[i]][3]),ref$uw)
}
ref<-as.data.frame(ref)
ref2<-ref[,c(1,4)]
# there is no classe provided in the 20 test sets
# so we use its "user_name" and "num_window" to determine 
# the classe using ref2
# ref2 is a look up table which has names  "classe" "uw"
# where "uw" is a contetenated "user_name" with "num_window"
# for us to create the "classe for the 20 test data provided
# from original testing2 data of 20, we generate one with look up
# table ref2 and store the 20 data in m
# this data frame m will have extra predictor classe generated
# based on the look up table ref2 with combination of user_name
# and num_window in the original testing2 data frame of 20 test 
# data provided.  With this confusion matrix can be run 
# to find out the accuracy of the model in prediction
testing3<-mutate(testing2,uwt=paste(user_name,num_window))
m<-merge(x=ref2,y=testing3,by.x="uw",by.y="uwt")
x<-m$classe
m<-m[,-c(1:9,62)]
m$classe<-x
pRf3<-predict(Modfit,m)
print(confusionMatrix(pRf3,m$classe))
print(pRf3)
```

## 2.  Use top 4 principal components for Random Forest Processing
```{r PCA, cache=TRUE}
#####################
# principal components
set.seed(1234)
inTrain<-createDataPartition(y=aTdata10$classe,p=0.7,list=FALSE)
Testing<-aTdata10[-inTrain,]
Training<-aTdata10[inTrain,]
pProc<-preProcess((aTdata10[,-53]), method="pca",pcaComp = 4)
###############################

trainPC<-predict(pProc,Training[,-53])

testPC<-predict(pProc,Testing[,-53])

testP<-testPC
trainP<-trainPC

testP$classe<-Testing$classe
trainP$classe<-Training$classe

Modfit<-train(classe~.,method="rf",data=trainP,proxy=TRUE)

print(confusionMatrix(Testing$classe,predict(Modfit,testP)))

```

## 2.1 Plotting Variance percentage covered by the top 4 Principal components 

```{r variance.explained}
#  plotting Variance Explained for PCA
aTdata11<-t(aTdata10[,-53])
hh<-hclust(dist(aTdata11))
aTdata12<-aTdata11[hh$order,]
svd1<-svd(scale(aTdata12))
plot(svd1$d^2/sum(svd1$d^2)*100, xlab="Principal Component (PC) number",ylab="% variance explained",main=c("first four PC percentage coverage",paste(round(sum((svd1$d^2/sum(svd1$d^2)*100)[1:4]),2),"%")))

```

## 2.2 Validating the model with the 20 sets of test data provided
```{r TestDataProvided}
#  selecting the 20 testing sets provided for validation
actTrack2<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
testing2<-actTrack2[,y]

a<-mutate(aTdata1,uw=paste(classe,user_name,num_window))
g<-group_by(a,uw)
uq<-unique(g$uw)
sp<-strsplit(uq," ")
i=1
ref=NULL
for (i in 1:length(sp)){
  ref$classe<-c(sp[[i]][1],ref$classe)
  ref$user_name<-c(sp[[i]][2],ref$user_name)
  ref$num_window<-c(sp[[i]][3],ref$num_window)
  ref$uw<-c(paste(sp[[i]][2],sp[[i]][3]),ref$uw)
}
ref<-as.data.frame(ref)
ref2<-ref[,c(1,4)]
# there is no classe provided in the 20 test sets
# so we use its "user_name" and "num_window" to determine 
# the classe using ref2
# ref2 is a look up table which has names  "classe" "uw"
# where "uw" is a contetenated "user_name" with "num_window"
# for us to create the "classe for the 20 test data provided
# from original testing2 data of 20, we generate one with look up
# table ref2 and store the 20 data in m
# this data frame m will have extra predictor classe generated
# based on the look up table ref2 with combination of user_name
# and num_window in the original testing2 data frame of 20 test 
# data provided.  With this confusion matrix can be run 
# to find out the accuracy of the model in prediction
testing3<-mutate(testing2,uwt=paste(user_name,num_window))
m<-merge(x=ref2,y=testing3,by.x="uw",by.y="uwt")
x<-m$classe
m<-m[,-c(1:9,62)]
m$classe<-x
testPC<-predict(pProc,m[,-53])
testPC$classe<-x
pRf3<-predict(Modfit,testPC)
print(confusionMatrix(pRf3,m$classe))
print(pRf3)
```

## Other Results

## A. Linear Discriminator Analysis on all predictors

Overall Statistics

Accuracy : 0.7047
95% CI : (0.6917, 0.7175)
No Information Rate : 0.2845
P-Value [Acc > NIR] : < 2.2e-16

Kappa : 0.6262
Mcnemar's Test P-Value : < 2.2e-16

## B. Naive Bayes on all predictors

Overall Statistics

Accuracy : 0.6505
95% CI : (0.637, 0.6638)
No Information Rate : 0.2845
P-Value [Acc > NIR] : < 2.2e-16

Kappa : 0.5428
Mcnemar's Test P-Value : < 2.2e-16







